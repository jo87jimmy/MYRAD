import torch  # å¼•å…¥ PyTorch
from dataset import get_data_transforms  # å¾ dataset.py è¼‰å…¥è³‡æ–™è½‰æ›å‡½å¼
from torchvision.datasets import ImageFolder  # ç”¨æ–¼å½±åƒè³‡æ–™å¤¾çš„è³‡æ–™é›†
import numpy as np  # æ•¸å€¼è¨ˆç®—å¥—ä»¶
import random  # äº‚æ•¸æ§åˆ¶
import os  # æª”æ¡ˆç³»çµ±æ“ä½œ
from torch.utils.data import DataLoader  # PyTorch çš„è³‡æ–™è¼‰å…¥å™¨
from dataset import MVTecDataset  # MVTec è³‡æ–™é›†é¡åˆ¥
import torch.backends.cudnn as cudnn  # CUDA cuDNN åŠ é€Ÿ
import argparse  # å‘½ä»¤åˆ—åƒæ•¸è™•ç†
from test import evaluation, evaluation_draem, visualization, visualizationDraem, dream_evaluation, evaluation2, test  # æ¸¬è©¦ã€è©•ä¼°èˆ‡å¯è¦–åŒ–å‡½å¼
from torch.nn import functional as F  # å¼•å…¥ PyTorch çš„å‡½å¼ä»‹é¢
from model_unet import ReconstructiveSubNetwork, DiscriminativeSubNetwork  # å‡è¨­ä½ çš„ DRAEM å®šç¾©åœ¨ models/draem.py
from student_models import StudentReconstructiveSubNetwork, StudentDiscriminativeSubNetwork
from loss import FocalLoss, SSIM
from data_loader import MVTecDRAEMTrainDataset
from torch import optim
from data_loader_val import MVTecDRAEMValidationDataset
# æ–°å¢ç†±åŠ›åœ–å¯è¦–åŒ–æ‰€éœ€çš„å‡½å¼åº«
from PIL import Image
import matplotlib.pyplot as plt
import torchvision.transforms as transforms


def setup_seed(seed):
    # è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—å¯é‡ç¾
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è­‰çµæœå¯é‡ç¾
    torch.backends.cudnn.benchmark = False  # é—œé–‰è‡ªå‹•æœ€ä½³åŒ–æœå°‹


# è’¸é¤¾æå¤±å‡½æ•¸
def distillation_loss(teacher_features, student_features):
    cos_loss = torch.nn.CosineSimilarity()
    if not isinstance(teacher_features, (list, tuple)):
        teacher_features, student_features = [teacher_features
                                              ], [student_features]

    loss = 0
    for i in range(len(teacher_features)):
        loss += torch.mean(1 - cos_loss(
            teacher_features[i].view(teacher_features[i].shape[0], -1),
            student_features[i].view(student_features[i].shape[0], -1)))
    return loss


def train(_arch_, _class_, epochs, save_pth_path):
    # è¨“ç·´æµç¨‹
    print(f"ğŸ”§ é¡åˆ¥: {_class_} | Epochs: {epochs}")

    device = 'cuda' if torch.cuda.is_available() else 'cpu'  # é¸æ“‡è£ç½®
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: {device}")

    # æ•™å¸«æ¨¡å‹ (å·²è¼‰å…¥æ¬Šé‡ä¸¦è¨­ç‚º eval æ¨¡å¼)
    teacher_model = ReconstructiveSubNetwork(in_channels=3, out_channels=3)
    teacher_model_seg = DiscriminativeSubNetwork(in_channels=6, out_channels=2)
    # === Step 2: è¼‰å…¥ checkpoint ===
    teacher_model_ckpt = torch.load(
        "DRAEM_seg_large_ae_large_0.0001_800_bs8_bottle_.pckl",
        map_location=device,
        weights_only=True)
    teacher_model_seg_ckpt = torch.load(
        "DRAEM_seg_large_ae_large_0.0001_800_bs8_bottle__seg.pckl",
        map_location=device,
        weights_only=True)
    teacher_model.load_state_dict(teacher_model_ckpt)
    teacher_model_seg.load_state_dict(teacher_model_seg_ckpt)
    # é‡è¦ï¼šè¼‰å…¥æ¬Šé‡å¾Œå†ç§»åˆ°è¨­å‚™
    teacher_model = teacher_model.to(device)
    teacher_model_seg = teacher_model_seg.to(device)
    teacher_model.eval()
    teacher_model_seg.eval()

    # å­¸ç”Ÿæ¨¡å‹
    # å®šç¾©ä¸€å€‹ dropout_rateï¼Œæ‚¨å¯ä»¥å°‡å…¶ä½œç‚º args çš„ä¸€éƒ¨åˆ†ï¼Œæˆ–åœ¨é€™è£¡ç¡¬ç·¨ç¢¼
    student_dropout_rate = 0.2  # å»ºè­°å¾ 0.1-0.3 ä¹‹é–“é–‹å§‹å˜—è©¦
    student_model = StudentReconstructiveSubNetwork(
        in_channels=3, out_channels=3,
        dropout_rate=student_dropout_rate)  # å‚³å…¥ dropout_rate
    student_model_seg = StudentDiscriminativeSubNetwork(
        in_channels=6, out_channels=2,
        dropout_rate=student_dropout_rate)  # å‚³å…¥ dropout_rate

    student_model = student_model.to(device)
    student_model_seg = student_model_seg.to(device)

    # === Step 3: ç‚ºå­¸ç”Ÿæ¨¡å‹å®šç¾©å„ªåŒ–å™¨å’Œå­¸ç¿’ç‡æ’ç¨‹å™¨ ===
    # å®šç¾©ä¸€å€‹ weight_decay å€¼ï¼Œæ‚¨å¯ä»¥å°‡å…¶ä½œç‚º args çš„ä¸€éƒ¨åˆ†ï¼Œæˆ–åœ¨é€™è£¡ç¡¬ç·¨ç¢¼
    optimizer_weight_decay = 1e-5  # å»ºè­°å¾ 1e-5 æˆ– 1e-4 é–‹å§‹å˜—è©¦
    optimizer = torch.optim.Adam([
        {
            "params": student_model.parameters(),
            "lr": args.lr,
            "weight_decay": optimizer_weight_decay  # æ·»åŠ  L2 æ­£å‰‡åŒ– (weight_decay)
        },
        {
            "params": student_model_seg.parameters(),
            "lr": args.lr,
            "weight_decay": optimizer_weight_decay  # æ·»åŠ  L2 æ­£å‰‡åŒ– (weight_decay)
        }
    ])
    scheduler = optim.lr_scheduler.MultiStepLR(
        optimizer,
        milestones=[args.epochs * 0.8, args.epochs * 0.9],
        gamma=0.2)

    # optimizer = torch.optim.Adam(list(student_model.parameters()) +
    #                              list(student_model_seg.parameters()),
    #                              lr=learning_rate,
    #                              betas=(0.5, 0.999))

    # === Step 4: å®šç¾©æ‰€æœ‰éœ€è¦çš„æå¤±å‡½æ•¸å’Œè’¸é¤¾è¶…åƒæ•¸ ===
    # ç¡¬æå¤± (Hard Loss) - å­¸ç”Ÿèˆ‡çœŸå¯¦æ¨™ç±¤æ¯”è¼ƒ
    loss_l2 = torch.nn.modules.loss.MSELoss()
    loss_ssim = SSIM()
    loss_focal = FocalLoss()

    # è’¸é¤¾æå¤± (Distillation Loss) - å­¸ç”Ÿèˆ‡æ•™å¸«æ¯”è¼ƒ
    loss_distill_recon_fn = torch.nn.modules.loss.MSELoss()
    # é‡å»ºéƒ¨åˆ†ï¼Œå­¸ç”Ÿæ¨¡ä»¿è€å¸«çš„è¼¸å‡ºï¼ŒMSE æˆ– L1 éƒ½å¯ä»¥
    loss_kldiv = torch.nn.KLDivLoss(
        reduction='batchmean')  # åˆ†å‰²éƒ¨åˆ†ï¼Œç”¨ KL æ•£åº¦è¡¡é‡æ©Ÿç‡åˆ†ä½ˆ

    # è’¸é¤¾è¶…åƒæ•¸
    T = 2.0  # æº«åº¦ (Temperature)ï¼Œè®“æ•™å¸«çš„è¼¸å‡ºæ›´å¹³æ»‘ï¼Œé€šå¸¸ > 1
    alpha = 0.5  # è’¸é¤¾æ¬Šé‡ï¼Œæ§åˆ¶è’¸é¤¾æå¤±åœ¨ç¸½æå¤±ä¸­çš„ä½”æ¯” (0.7 ä»£è¡¨ 70%)

    # === Step 5: æº–å‚™ Dataset å’Œ DataLoader ===
    print("Step 5: Preparing Dataset and DataLoader...")

    train_path = f'./mvtec/{_class_}/train'  # è¨“ç·´è³‡æ–™è·¯å¾‘
    anomaly_source_path = f'./dtd/images'
    dataset = MVTecDRAEMTrainDataset(train_path + "/good/",
                                     anomaly_source_path,
                                     resize_shape=[256, 256])
    dataloader = DataLoader(dataset,
                            batch_size=args.bs,
                            shuffle=True,
                            num_workers=8)

    # --- æ·»åŠ é©—è­‰è³‡æ–™è¼‰å…¥å™¨ ---
    val_path = f'./mvtec/{_class_}/test'  # é©—è­‰è³‡æ–™è·¯å¾‘ (MVTec AD çš„æ¸¬è©¦é›†)
    val_dataset = MVTecDRAEMValidationDataset(val_path,
                                              resize_shape=[256, 256])
    val_dataloader = DataLoader(
        val_dataset,
        batch_size=args.bs,  # é©—è­‰é›†å¯ä»¥èˆ‡è¨“ç·´é›†ä½¿ç”¨ç›¸åŒ batch_size
        shuffle=False,  # é©—è­‰é›†é€šå¸¸ä¸éœ€è¦æ‰“äº‚
        num_workers=8)  # ä¿æŒèˆ‡è¨“ç·´é›†ç›¸åŒçš„ num_workers æˆ–æ ¹æ“šéœ€æ±‚èª¿æ•´
    print("Validation DataLoader prepared.")

    # === Step 6: å¯¦ç¾æ ¸å¿ƒè¨“ç·´è¿´åœˆ ===
    print("Step 6: Starting the training loop...")
    best_val_loss = float('inf')

    for epoch in range(args.epochs):
        student_model.train()  # ç¢ºä¿å­¸ç”Ÿæ¨¡å‹è™•æ–¼è¨“ç·´æ¨¡å¼ï¼ŒDropout å•Ÿç”¨
        student_model_seg.train()

        running_loss = 0.0

        print(f"Epoch: {epoch+1}/{args.epochs}")
        for i_batch, sample_batched in enumerate(dataloader):
            # æº–å‚™è³‡æ–™
            gray_batch = sample_batched["image"].to(device)
            aug_gray_batch = sample_batched["augmented_image"].to(device)
            anomaly_mask = sample_batched["anomaly_mask"].to(device)

            # --- æ•™å¸«æ¨¡å‹å‰å‘å‚³æ’­ (ä¸è¨ˆç®—æ¢¯åº¦) ---
            with torch.no_grad():
                teacher_rec = teacher_model(aug_gray_batch)
                teacher_joined_in = torch.cat((teacher_rec, aug_gray_batch),
                                              dim=1)
                teacher_out_mask_logits = teacher_model_seg(teacher_joined_in)

            # --- å­¸ç”Ÿæ¨¡å‹å‰å‘å‚³æ’­ ---
            student_rec = student_model(aug_gray_batch)
            student_joined_in = torch.cat((student_rec, aug_gray_batch), dim=1)
            student_out_mask_logits = student_model_seg(student_joined_in)

            # --- è¨ˆç®—æå¤± ---
            # 1. ç¡¬æå¤± (å­¸ç”Ÿ vs. Ground Truth)
            loss_hard_l2 = loss_l2(student_rec, gray_batch)
            loss_hard_ssim = loss_ssim(student_rec, gray_batch)
            student_out_mask_sm = F.softmax(student_out_mask_logits, dim=1)
            loss_hard_segment = loss_focal(student_out_mask_sm, anomaly_mask)
            loss_hard = loss_hard_l2 + loss_hard_ssim + loss_hard_segment

            # 2. è’¸é¤¾æå¤± (å­¸ç”Ÿ vs. æ•™å¸«)
            #   a. é‡å»ºè’¸é¤¾æå¤±
            loss_distill_recon = loss_distill_recon_fn(student_rec,
                                                       teacher_rec)
            #   b. åˆ†å‰²è’¸é¤¾æå¤± (KL æ•£åº¦)
            p_student = F.log_softmax(student_out_mask_logits / T, dim=1)
            p_teacher = F.softmax(teacher_out_mask_logits / T, dim=1)
            loss_distill_segment = loss_kldiv(p_student, p_teacher) * (
                T * T)  # ä¹˜ä¸Š T^2 ä»¥ä¿æŒæ¢¯åº¦å¤§å°
            loss_distill = loss_distill_recon + loss_distill_segment

            # 3. ç¸½æå¤± (åŠ æ¬Šçµ„åˆ)
            loss = (1 - alpha) * loss_hard + alpha * loss_distill

            # --- åå‘å‚³æ’­èˆ‡å„ªåŒ– (åªæ›´æ–°å­¸ç”Ÿæ¨¡å‹) ---
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # === ä¿®æ”¹ï¼šç´¯è¨ˆç•¶å‰ batch çš„æå¤± ===
            running_loss += loss.item()

            if i_batch % 100 == 0:
                print(
                    f"  Batch {i_batch}/{len(dataloader)}, Total Loss: {loss.item():.4f}, "
                    f"Hard Loss: {loss_hard.item():.4f}, Distill Loss: {loss_distill.item():.4f}"
                )

        # è¨ˆç®—æ­¤ epoch çš„å¹³å‡æå¤±
        epoch_loss = running_loss / len(dataloader)
        print(f"Epoch {epoch+1} Average Loss: {epoch_loss:.4f}")

        # === é©—è­‰éšæ®µ ===
        student_model.eval()  # è¨­ç½®å­¸ç”Ÿæ¨¡å‹ç‚ºè©•ä¼°æ¨¡å¼ï¼ŒDropout ç¦ç”¨
        student_model_seg.eval()
        val_running_loss = 0.0

        with torch.no_grad():  # é©—è­‰éšæ®µä¸éœ€è¦è¨ˆç®—æ¢¯åº¦
            for i_batch_val, sample_batched_val in enumerate(
                    val_dataloader):  # å‡è¨­æœ‰ä¸€å€‹ val_dataloader
                gray_batch_val = sample_batched_val["image"].to(device)
                aug_gray_batch_val = sample_batched_val["augmented_image"].to(
                    device)
                anomaly_mask_val = sample_batched_val["anomaly_mask"].to(
                    device)

                # --- æ•™å¸«æ¨¡å‹å‰å‘å‚³æ’­ (ä¸è¨ˆç®—æ¢¯åº¦) ---
                teacher_rec_val = teacher_model(aug_gray_batch_val)
                teacher_joined_in_val = torch.cat(
                    (teacher_rec_val, aug_gray_batch_val), dim=1)
                teacher_out_mask_logits_val = teacher_model_seg(
                    teacher_joined_in_val)

                # --- å­¸ç”Ÿæ¨¡å‹å‰å‘å‚³æ’­ ---
                student_rec_val = student_model(aug_gray_batch_val)
                student_joined_in_val = torch.cat(
                    (student_rec_val, aug_gray_batch_val), dim=1)
                student_out_mask_logits_val = student_model_seg(
                    student_joined_in_val)

                # --- è¨ˆç®—é©—è­‰æå¤± ---
                loss_hard_l2_val = loss_l2(student_rec_val, gray_batch_val)
                loss_hard_ssim_val = loss_ssim(student_rec_val, gray_batch_val)
                student_out_mask_sm_val = F.softmax(
                    student_out_mask_logits_val, dim=1)
                loss_hard_segment_val = loss_focal(student_out_mask_sm_val,
                                                   anomaly_mask_val)
                loss_hard_val = loss_hard_l2_val + loss_hard_ssim_val + loss_hard_segment_val

                loss_distill_recon_val = loss_distill_recon_fn(
                    student_rec_val, teacher_rec_val)
                p_student_val = F.log_softmax(student_out_mask_logits_val / T,
                                              dim=1)
                p_teacher_val = F.softmax(teacher_out_mask_logits_val / T,
                                          dim=1)
                loss_distill_segment_val = loss_kldiv(p_student_val,
                                                      p_teacher_val) * (T * T)
                loss_distill_val = loss_distill_recon_val + loss_distill_segment_val

                val_loss = (1 -
                            alpha) * loss_hard_val + alpha * loss_distill_val
                val_running_loss += val_loss.item()

        epoch_val_loss = val_running_loss / len(val_dataloader)
        print(f"Epoch {epoch+1} Average Validation Loss: {epoch_val_loss:.4f}")

        # æª¢æŸ¥æ˜¯å¦ç‚ºæœ€ä½³æå¤±ï¼Œè‹¥æ˜¯å‰‡å„²å­˜æ¬Šé‡
        if epoch_loss < best_val_loss:
            best_val_loss = epoch_loss
            student_run_name = f"{_arch_}_student_{_class_}"
            torch.save(student_model.state_dict(),
                       os.path.join(save_pth_path, student_run_name + ".pckl"))
            torch.save(
                student_model_seg.state_dict(),
                os.path.join(save_pth_path, student_run_name + "_seg.pckl"))

            print(f"ğŸ‰ æ‰¾åˆ°æ–°çš„æœ€ä½³æ¨¡å‹ï¼Loss: {best_val_loss:.4f}ã€‚å·²å„²å­˜è‡³ {save_pth_path}")

        scheduler.step()
    print("è¨“ç·´å®Œæˆï¼")


def generate_anomaly_heatmap(image_path,
                             student_model,
                             student_model_seg,
                             device,
                             resize_shape=[256, 256]):
    """
    ä½¿ç”¨è¨“ç·´å¥½çš„å­¸ç”Ÿæ¨¡å‹ç‚ºçµ¦å®šè¼¸å…¥å½±åƒç”Ÿæˆç•°å¸¸ç†±åŠ›åœ–ã€‚

    Args:
        image_path (str): è¼¸å…¥å½±åƒçš„è·¯å¾‘ã€‚
        student_model (torch.nn.Module): è¨“ç·´å¥½çš„å­¸ç”Ÿé‡å»ºå­ç¶²è·¯ã€‚
        student_model_seg (torch.nn.Module): è¨“ç·´å¥½çš„å­¸ç”Ÿåˆ¤åˆ¥å­ç¶²è·¯ã€‚
        device (str or torch.device): åŸ·è¡Œæ¨è«–çš„è£ç½® ('cuda' æˆ– 'cpu')ã€‚
        resize_shape (list): å½±åƒç¸®æ”¾çš„ç›®æ¨™å°ºå¯¸ (é«˜åº¦, å¯¬åº¦)ã€‚

    Returns:
        tuple: (numpy.ndarray, PIL.Image.Image) ç•°å¸¸ç†±åŠ›åœ– (NumPy é™£åˆ—) å’ŒåŸå§‹å½±åƒ (å·²ç¸®æ”¾çš„ PIL.Image ç‰©ä»¶)ã€‚
    """
    student_model.eval()  # è¨­å®šæ¨¡å‹ç‚ºè©•ä¼°æ¨¡å¼
    student_model_seg.eval()

    # å®šç¾©å½±åƒé è™•ç†è½‰æ›
    # èˆ‡ MVTecDRAEMTrainDataset ä¸­çš„æ­£è¦åŒ–ä¿æŒä¸€è‡´ (é€šå¸¸æ˜¯ [0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    transform = transforms.Compose([
        transforms.Resize(resize_shape),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])

    # è¼‰å…¥ä¸¦é è™•ç†å½±åƒ
    img = Image.open(image_path).convert('RGB')
    # ç‚ºäº†å¯è¦–åŒ–ï¼Œä¿ç•™ä¸€å€‹æœªæ­£è¦åŒ–ä½†å·²ç¸®æ”¾çš„åŸå§‹å½±åƒå‰¯æœ¬
    original_img_resized = img.resize((resize_shape[1], resize_shape[0]))
    img_tensor = transform(img).unsqueeze(0).to(device)  # æ–°å¢æ‰¹æ¬¡ç¶­åº¦

    with torch.no_grad():  # åœ¨æ¨è«–æ™‚ä¸è¨ˆç®—æ¢¯åº¦
        # å­¸ç”Ÿé‡å»ºç¶²è·¯æ¨è«–
        student_rec = student_model(img_tensor)

        # æº–å‚™å­¸ç”Ÿåˆ¤åˆ¥ç¶²è·¯çš„è¼¸å…¥ (é‡å»ºå½±åƒ + åŸå§‹å½±åƒ)
        student_joined_in = torch.cat((student_rec, img_tensor), dim=1)

        # å­¸ç”Ÿåˆ¤åˆ¥ç¶²è·¯æ¨è«–
        student_out_mask_logits = student_model_seg(student_joined_in)

        # æ‡‰ç”¨ Softmax å–å¾—ç•°å¸¸æ©Ÿç‡
        # åˆ¤åˆ¥ç¶²è·¯è¼¸å‡ºæœ‰ 2 å€‹é€šé“ï¼š[æ­£å¸¸æ©Ÿç‡ logits, ç•°å¸¸æ©Ÿç‡ logits]
        # æˆ‘å€‘å–ç•°å¸¸é¡åˆ¥ (é€šé“ 1) çš„æ©Ÿç‡
        anomaly_map = F.softmax(student_out_mask_logits,
                                dim=1)[:, 1, :, :].squeeze(0)

        # ç§»è‡³ CPU ä¸¦è½‰æ›ç‚º NumPy é™£åˆ—ä»¥ä¾¿å¯è¦–åŒ–
        anomaly_map_np = anomaly_map.cpu().numpy()

    return anomaly_map_np, original_img_resized


if __name__ == '__main__':
    import argparse
    import pandas as pd
    import os
    import torch

    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser()
    parser.add_argument('--category', default='bottle', type=str)  # è¨“ç·´é¡åˆ¥
    parser.add_argument('--epochs', default=25, type=int)  # è¨“ç·´å›åˆæ•¸
    parser.add_argument('--arch', default='wres50', type=str)  # æ¨¡å‹æ¶æ§‹
    parser.add_argument('--bs', action='store', type=int, required=True)
    parser.add_argument('--lr', action='store', type=float, required=True)
    parser.add_argument('--test_image_path',
                        type=str,
                        help='è·¯å¾‘åˆ°ä¸€å€‹ç”¨æ–¼ç”Ÿæˆç†±åŠ›åœ–çš„æ¸¬è©¦å½±åƒ (è¨“ç·´å¾ŒåŸ·è¡Œ)ã€‚',
                        default=None)  # æ–°å¢åƒæ•¸
    parser.add_argument(
        '--student_dropout_rate',
        type=float,
        default=0.2,
        help='å­¸ç”Ÿæ¨¡å‹è¨“ç·´å’Œè¼‰å…¥æ™‚ä½¿ç”¨çš„ Dropout Rateã€‚')  # å°‡ Dropout Rate å¯é…ç½®åŒ–
    args = parser.parse_args()

    setup_seed(111)  # å›ºå®šéš¨æ©Ÿç¨®å­
    save_pth_path = f"pths/best_{args.arch}_{args.category}"

    # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
    save_pth_dir = save_pth_path if save_pth_path else 'pths/best'
    os.makedirs(save_pth_dir, exist_ok=True)

    # é–‹å§‹è¨“ç·´ï¼Œä¸¦æ¥æ”¶æœ€ä½³æ¨¡å‹è·¯å¾‘èˆ‡çµæœ
    train(args.arch, args.category, args.epochs, save_pth_path)

    # --- ç¼ºé™·æª¢æ¸¬ç†±åŠ›åœ–ç”Ÿæˆå€å¡Š ---
    if args.test_image_path:
        print("\n--- æ­£åœ¨ç”Ÿæˆç¼ºé™·æª¢æ¸¬ç†±åŠ›åœ– ---")
        device = 'cuda' if torch.cuda.is_available() else 'cpu'

        # è¼‰å…¥å­¸ç”Ÿæ¨¡å‹æ¬Šé‡
        # é€™è£¡ä½¿ç”¨çš„ dropout_rate æ‡‰èˆ‡è¨“ç·´æ™‚ä½¿ç”¨çš„ä¿æŒä¸€è‡´
        student_model = StudentReconstructiveSubNetwork(
            in_channels=3,
            out_channels=3,
            dropout_rate=args.student_dropout_rate).to(device)
        student_model_seg = StudentDiscriminativeSubNetwork(
            in_channels=6,
            out_channels=2,
            dropout_rate=args.student_dropout_rate).to(device)

        student_run_name = f"{args.arch}_student_{args.category}"
        student_model_path = os.path.join(save_pth_path,
                                          student_run_name + ".pckl")
        student_model_seg_path = os.path.join(save_pth_path,
                                              student_run_name + "_seg.pckl")

        if os.path.exists(student_model_path) and os.path.exists(
                student_model_seg_path):
            student_model.load_state_dict(
                torch.load(student_model_path, map_location=device))
            student_model_seg.load_state_dict(
                torch.load(student_model_seg_path, map_location=device))
            print(
                f"âœ… å·²æˆåŠŸè¼‰å…¥å­¸ç”Ÿæ¨¡å‹æ¬Šé‡: {student_model_path} åŠ {student_model_seg_path}"
            )

            # ç”Ÿæˆç†±åŠ›åœ–
            anomaly_heatmap, original_image_resized = generate_anomaly_heatmap(
                args.test_image_path, student_model, student_model_seg, device)

            # å¯è¦–åŒ–çµæœ
            plt.figure(figsize=(12, 6))

            plt.subplot(1, 2, 1)
            plt.imshow(original_image_resized)
            plt.title("åŸå§‹å½±åƒ (Resized)")
            plt.axis('off')

            plt.subplot(1, 2, 2)
            # å°‡ç†±åŠ›åœ–ç–ŠåŠ åœ¨åŸå§‹å½±åƒä¸Š
            plt.imshow(original_image_resized, cmap='gray')  # èƒŒæ™¯é¡¯ç¤ºåŸå§‹å½±åƒ
            plt.imshow(anomaly_heatmap, cmap='jet', alpha=0.5, vmin=0,
                       vmax=1)  # ç–ŠåŠ ç†±åŠ›åœ–
            plt.colorbar(label='ç•°å¸¸æ©Ÿç‡')
            plt.title("ç¼ºé™·ç†±åŠ›åœ–")
            plt.axis('off')

            plt.tight_layout()
            plt.show()

            # (å¯é¸) å„²å­˜ç†±åŠ›åœ–åˆ°æª”æ¡ˆ
            heatmap_filename = os.path.join(
                save_pth_path,
                f"heatmap_{os.path.basename(args.test_image_path)}")
            plt.savefig(heatmap_filename)
            print(f"ç†±åŠ›åœ–å·²å„²å­˜è‡³: {heatmap_filename}")

        else:
            print(
                f"âŒ æ‰¾ä¸åˆ°å­¸ç”Ÿæ¨¡å‹æ¬Šé‡ï¼Œè«‹ç¢ºèªè·¯å¾‘: {student_model_path} æˆ– {student_model_seg_path} æ˜¯å¦å­˜åœ¨ã€‚"
            )
    else:
        print("\nå¦‚éœ€ç”Ÿæˆç†±åŠ›åœ–ï¼Œè«‹åœ¨å‘½ä»¤åˆ—ä¸­æŒ‡å®š '--test_image_path <å½±åƒè·¯å¾‘>'ã€‚")
