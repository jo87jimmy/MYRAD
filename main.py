import torch  # å¼•å…¥ PyTorch
from dataset import get_data_transforms  # å¾ dataset.py è¼‰å…¥è³‡æ–™è½‰æ›å‡½å¼
from torchvision.datasets import ImageFolder  # ç”¨æ–¼å½±åƒè³‡æ–™å¤¾çš„è³‡æ–™é›†
import numpy as np  # æ•¸å€¼è¨ˆç®—å¥—ä»¶
import random  # äº‚æ•¸æ§åˆ¶
import os  # æª”æ¡ˆç³»çµ±æ“ä½œ
from torch.utils.data import DataLoader  # PyTorch çš„è³‡æ–™è¼‰å…¥å™¨
from dataset import MVTecDataset  # MVTec è³‡æ–™é›†é¡åˆ¥
import torch.backends.cudnn as cudnn  # CUDA cuDNN åŠ é€Ÿ
import argparse  # å‘½ä»¤åˆ—åƒæ•¸è™•ç†
from test import evaluation, evaluation_draem, visualization, visualizationDraem, dream_evaluation, evaluation2, test  # æ¸¬è©¦ã€è©•ä¼°èˆ‡å¯è¦–åŒ–å‡½å¼
from torch.nn import functional as F  # å¼•å…¥ PyTorch çš„å‡½å¼ä»‹é¢
from model_unet import ReconstructiveSubNetwork, DiscriminativeSubNetwork  # å‡è¨­ä½ çš„ DRAEM å®šç¾©åœ¨ models/draem.py
from student_models import StudentReconstructiveSubNetwork, StudentDiscriminativeSubNetwork
from loss import FocalLoss, SSIM
from data_loader import MVTecDRAEMTrainDataset
from torch import optim


def setup_seed(seed):
    # è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—å¯é‡ç¾
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è­‰çµæœå¯é‡ç¾
    torch.backends.cudnn.benchmark = False  # é—œé–‰è‡ªå‹•æœ€ä½³åŒ–æœå°‹


# è’¸é¤¾æå¤±å‡½æ•¸
def distillation_loss(teacher_features, student_features):
    cos_loss = torch.nn.CosineSimilarity()
    if not isinstance(teacher_features, (list, tuple)):
        teacher_features, student_features = [teacher_features
                                              ], [student_features]

    loss = 0
    for i in range(len(teacher_features)):
        loss += torch.mean(1 - cos_loss(
            teacher_features[i].view(teacher_features[i].shape[0], -1),
            student_features[i].view(student_features[i].shape[0], -1)))
    return loss


def train(_arch_, _class_, epochs, save_pth_path):
    # è¨“ç·´æµç¨‹
    print(f"ğŸ”§ é¡åˆ¥: {_class_} | Epochs: {epochs}")
    learning_rate = 0.005  # å­¸ç¿’ç‡
    # batch_size = 16 # æ‰¹æ¬¡å¤§å°
    image_size = 256  # è¼¸å…¥å½±åƒå¤§å°

    device = 'cuda' if torch.cuda.is_available() else 'cpu'  # é¸æ“‡è£ç½®
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: {device}")

    # # è³‡æ–™è½‰æ›
    # data_transform, gt_transform = get_data_transforms(image_size, image_size)
    # train_path = f'./mvtec/{_class_}/train'  # è¨“ç·´è³‡æ–™è·¯å¾‘
    # test_path = f'./mvtec/{_class_}'  # æ¸¬è©¦è³‡æ–™è·¯å¾‘

    # # è¼‰å…¥è¨“ç·´èˆ‡æ¸¬è©¦è³‡æ–™
    # train_data = ImageFolder(root=train_path, transform=data_transform)
    # test_data = MVTecDataset(root=test_path,
    #                          transform=data_transform,
    #                          gt_transform=gt_transform,
    #                          phase="test")

    # # å»ºç«‹ DataLoader
    # train_dataloader = torch.utils.data.DataLoader(train_data,
    #                                                batch_size=batch_size,
    #                                                shuffle=True)
    # test_dataloader = torch.utils.data.DataLoader(test_data,
    #                                               batch_size=1,
    #                                               shuffle=False)

    # æ•™å¸«æ¨¡å‹ (å·²è¼‰å…¥æ¬Šé‡ä¸¦è¨­ç‚º eval æ¨¡å¼)
    teacher_model = ReconstructiveSubNetwork(in_channels=3, out_channels=3)
    teacher_model_seg = DiscriminativeSubNetwork(in_channels=6, out_channels=2)
    # === Step 2: è¼‰å…¥ checkpoint ===
    teacher_model_ckpt = torch.load(
        "DRAEM_seg_large_ae_large_0.0001_800_bs8_bottle_.pckl",
        map_location=device,
        weights_only=True)
    teacher_model_seg_ckpt = torch.load(
        "DRAEM_seg_large_ae_large_0.0001_800_bs8_bottle__seg.pckl",
        map_location=device,
        weights_only=True)
    teacher_model.load_state_dict(teacher_model_ckpt)
    teacher_model_seg.load_state_dict(teacher_model_seg_ckpt)
    # é‡è¦ï¼šè¼‰å…¥æ¬Šé‡å¾Œå†ç§»åˆ°è¨­å‚™
    teacher_model = teacher_model.to(device)
    teacher_model_seg = teacher_model_seg.to(device)
    teacher_model.eval()
    teacher_model_seg.eval()

    # å­¸ç”Ÿæ¨¡å‹
    student_model = StudentReconstructiveSubNetwork(in_channels=3,
                                                    out_channels=3)
    student_model_seg = StudentDiscriminativeSubNetwork(in_channels=6,
                                                        out_channels=2)
    student_model = student_model.to(device)
    student_model_seg = student_model_seg.to(device)

    # === Step 3: ç‚ºå­¸ç”Ÿæ¨¡å‹å®šç¾©å„ªåŒ–å™¨å’Œå­¸ç¿’ç‡æ’ç¨‹å™¨ ===
    optimizer = torch.optim.Adam([{
        "params": student_model.parameters(),
        "lr": args.lr
    }, {
        "params": student_model_seg.parameters(),
        "lr": args.lr
    }])
    scheduler = optim.lr_scheduler.MultiStepLR(
        optimizer,
        milestones=[args.epochs * 0.8, args.epochs * 0.9],
        gamma=0.2)

    # optimizer = torch.optim.Adam(list(student_model.parameters()) +
    #                              list(student_model_seg.parameters()),
    #                              lr=learning_rate,
    #                              betas=(0.5, 0.999))

    # === Step 4: å®šç¾©æ‰€æœ‰éœ€è¦çš„æå¤±å‡½æ•¸å’Œè’¸é¤¾è¶…åƒæ•¸ ===
    # ç¡¬æå¤± (Hard Loss) - å­¸ç”Ÿèˆ‡çœŸå¯¦æ¨™ç±¤æ¯”è¼ƒ
    loss_l2 = torch.nn.modules.loss.MSELoss()
    loss_ssim = SSIM()
    loss_focal = FocalLoss()

    # è’¸é¤¾æå¤± (Distillation Loss) - å­¸ç”Ÿèˆ‡æ•™å¸«æ¯”è¼ƒ
    loss_distill_recon_fn = torch.nn.modules.loss.MSELoss()
    # é‡å»ºéƒ¨åˆ†ï¼Œå­¸ç”Ÿæ¨¡ä»¿è€å¸«çš„è¼¸å‡ºï¼ŒMSE æˆ– L1 éƒ½å¯ä»¥
    loss_kldiv = torch.nn.KLDivLoss(
        reduction='batchmean')  # åˆ†å‰²éƒ¨åˆ†ï¼Œç”¨ KL æ•£åº¦è¡¡é‡æ©Ÿç‡åˆ†ä½ˆ

    # è’¸é¤¾è¶…åƒæ•¸
    T = 4.0  # æº«åº¦ (Temperature)ï¼Œè®“æ•™å¸«çš„è¼¸å‡ºæ›´å¹³æ»‘ï¼Œé€šå¸¸ > 1
    alpha = 0.7  # è’¸é¤¾æ¬Šé‡ï¼Œæ§åˆ¶è’¸é¤¾æå¤±åœ¨ç¸½æå¤±ä¸­çš„ä½”æ¯” (0.7 ä»£è¡¨ 70%)

    # === Step 5: æº–å‚™ Dataset å’Œ DataLoader ===
    print("Step 5: Preparing Dataset and DataLoader...")

    train_path = f'./mvtec/{_class_}/train'  # è¨“ç·´è³‡æ–™è·¯å¾‘
    # test_path = f'./mvtec/{_class_}'  # æ¸¬è©¦è³‡æ–™è·¯å¾‘
    anomaly_source_path = f'./dtd/images'
    dataset = MVTecDRAEMTrainDataset(train_path + "/good/",
                                     anomaly_source_path,
                                     resize_shape=[256, 256])
    dataloader = DataLoader(dataset,
                            batch_size=args.bs,
                            shuffle=True,
                            num_workers=8)

    # === Step 6: å¯¦ç¾æ ¸å¿ƒè¨“ç·´è¿´åœˆ ===
    print("Step 6: Starting the training loop...")
    n_iter = 0
    for epoch in range(args.epochs):
        student_model.train()  # ç¢ºä¿å­¸ç”Ÿæ¨¡å‹è™•æ–¼è¨“ç·´æ¨¡å¼
        student_model_seg.train()

        print(f"Epoch: {epoch+1}/{args.epochs}")
        for i_batch, sample_batched in enumerate(dataloader):
            # æº–å‚™è³‡æ–™
            gray_batch = sample_batched["image"].to(device)
            aug_gray_batch = sample_batched["augmented_image"].to(device)
            anomaly_mask = sample_batched["anomaly_mask"].to(device)

            # --- æ•™å¸«æ¨¡å‹å‰å‘å‚³æ’­ (ä¸è¨ˆç®—æ¢¯åº¦) ---
            with torch.no_grad():
                teacher_rec = teacher_model(aug_gray_batch)
                teacher_joined_in = torch.cat((teacher_rec, aug_gray_batch),
                                              dim=1)
                teacher_out_mask_logits = teacher_model_seg(teacher_joined_in)

            # --- å­¸ç”Ÿæ¨¡å‹å‰å‘å‚³æ’­ ---
            student_rec = student_model(aug_gray_batch)
            student_joined_in = torch.cat((student_rec, aug_gray_batch), dim=1)
            student_out_mask_logits = student_model_seg(student_joined_in)

            # --- è¨ˆç®—æå¤± ---
            # 1. ç¡¬æå¤± (å­¸ç”Ÿ vs. Ground Truth)
            loss_hard_l2 = loss_l2(student_rec, gray_batch)
            loss_hard_ssim = loss_ssim(student_rec, gray_batch)
            student_out_mask_sm = F.softmax(student_out_mask_logits, dim=1)
            loss_hard_segment = loss_focal(student_out_mask_sm, anomaly_mask)
            loss_hard = loss_hard_l2 + loss_hard_ssim + loss_hard_segment

            # 2. è’¸é¤¾æå¤± (å­¸ç”Ÿ vs. æ•™å¸«)
            #   a. é‡å»ºè’¸é¤¾æå¤±
            loss_distill_recon = loss_distill_recon_fn(student_rec,
                                                       teacher_rec)
            #   b. åˆ†å‰²è’¸é¤¾æå¤± (KL æ•£åº¦)
            p_student = F.log_softmax(student_out_mask_logits / T, dim=1)
            p_teacher = F.softmax(teacher_out_mask_logits / T, dim=1)
            loss_distill_segment = loss_kldiv(p_student, p_teacher) * (
                T * T)  # ä¹˜ä¸Š T^2 ä»¥ä¿æŒæ¢¯åº¦å¤§å°
            loss_distill = loss_distill_recon + loss_distill_segment

            # 3. ç¸½æå¤± (åŠ æ¬Šçµ„åˆ)
            loss = (1 - alpha) * loss_hard + alpha * loss_distill

            # --- åå‘å‚³æ’­èˆ‡å„ªåŒ– (åªæ›´æ–°å­¸ç”Ÿæ¨¡å‹) ---
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if i_batch % 100 == 0:  # æ¯ 100 å€‹ batch æ‰“å°ä¸€æ¬¡ log
                print(
                    f"  Batch {i_batch}/{len(dataloader)}, Total Loss: {loss.item():.4f}, "
                    f"Hard Loss: {loss_hard.item():.4f}, Distill Loss: {loss_distill.item():.4f}"
                )
            n_iter += 1

        scheduler.step()

    # === Step 7: å„²å­˜è¨“ç·´å¥½çš„å­¸ç”Ÿæ¨¡å‹ ===
    print("Step 7: Saving the trained student model...")
    # ç‚ºå­¸ç”Ÿæ¨¡å‹è¨­å®šä¸€å€‹æ–°çš„å„²å­˜åç¨±
    student_run_name = f"{_arch_}_student_{_class_}"
    torch.save(student_model.state_dict(),
               os.path.join(save_pth_path, student_run_name + ".pckl"))
    torch.save(student_model_seg.state_dict(),
               os.path.join(save_pth_path, student_run_name + "_seg.pckl"))

    print(f"âœ… æ¨¡å‹å·²è¨“ç·´ä¸¦å„²å­˜è‡³ {save_pth_path}")

    # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
    # save_pth_dir = save_pth_path if save_pth_path else 'pths/best'
    # os.makedirs(save_pth_dir, exist_ok=True)

    # # è¨­å®šæœ€ä½³æ¬Šé‡æª”æ¡ˆå­˜æ”¾è·¯å¾‘
    # best_ckp_path = os.path.join(save_pth_dir, f'best_{_arch_}_{_class_}.pth')

    # # åˆå§‹åŒ–æœ€ä½³åˆ†æ•¸
    # best_score = -1

    # # è¨“ç·´è¿´åœˆ
    # for epoch in range(epochs):
    #     student_encoder.train()
    #     student_decoder.train()
    #     loss_list = []

    #     for img, label in train_dataloader:
    #         img = img.to(device)

    #         # æ•™å¸«æ¨¡å‹æ¨ç†
    #         with torch.no_grad():
    #             teacher_recon = teacher_encoder(img)
    #             teacher_input = torch.cat([img, teacher_recon], dim=1)
    #             teacher_seg = teacher_decoder(teacher_input)

    #         # å­¸ç”Ÿæ¨¡å‹æ¨ç†
    #         student_recon = student_encoder(img)
    #         student_input = torch.cat([img, student_recon], dim=1)
    #         student_seg = student_decoder(student_input)

    #         # è’¸é¤¾æå¤±ï¼šæ¯”è¼ƒç›¸åŒèªç¾©çš„è¼¸å‡º
    #         recon_loss = distillation_loss(teacher_recon, student_recon)
    #         seg_loss = distillation_loss(teacher_seg, student_seg)

    #         total_loss = recon_loss + seg_loss

    #         optimizer.zero_grad()
    #         total_loss.backward()  # ä¿®æ­£ï¼šä½¿ç”¨ total_loss
    #         optimizer.step()
    #         loss_list.append(total_loss.item())

    #     print(
    #         f"ğŸ“˜ Epoch [{epoch + 1}/{epochs}] | Loss: {np.mean(loss_list):.4f}")

    #     # æ¯å€‹ epoch éƒ½é€²è¡Œä¸€æ¬¡è©•ä¼°ï¼ˆä½¿ç”¨å­¸ç”Ÿæ¨¡å‹ï¼‰
    #     # éœ€è¦æ·»åŠ  bn å±¤
    #     #torch.nn.Identity() ä½œç‚ºä¸€å€‹æ†ç­‰æ˜ å°„å±¤ï¼Œä¸æœƒæ”¹è®Šè¼¸å…¥æ•¸æ“šï¼Œåªæ˜¯ç‚ºäº†æ»¿è¶³ evaluation å‡½æ•¸çš„åƒæ•¸è¦æ±‚
    #     #ç”±æ–¼ torch.nn.Identity() ä¸æ”¹è®Šè¼¸å…¥ï¼Œæ‰€ä»¥ bn(inputs) ç­‰åŒæ–¼ç›´æ¥å‚³é inputsï¼Œé€™æ¨£å°±èƒ½è®“æ‚¨çš„ DREAM æ¶æ§‹æ­£å¸¸å·¥ä½œã€‚
    #     # bn = torch.nn.Identity()  # æˆ–è€…ä½¿ç”¨é©ç•¶çš„ batch normalization å±¤
    #     auroc_px, auroc_sp, aupro_px = dream_evaluation(student_encoder,
    #                                             #   bn,
    #                                               student_decoder,
    #                                               test_dataloader, device)
    #     # auroc_px, auroc_sp, aupro_px = evaluation(student_encoder,
    #     #                                           student_decoder,
    #     #                                           test_dataloader, device)
    #     print(f"ğŸ” è©•ä¼° | Pixel AUROC: {auroc_px:.3f}")

    #     # å¦‚æœè¡¨ç¾æ›´å¥½å‰‡å„²å­˜å­¸ç”Ÿæ¨¡å‹
    #     if auroc_px > best_score:
    #         best_score = auroc_px
    #         torch.save(
    #             {
    #                 'encoder': student_encoder.state_dict(),
    #                 'decoder': student_decoder.state_dict()
    #             }, best_ckp_path)
    #         print(f"ğŸ’¾ æ›´æ–°æœ€ä½³æ¨¡å‹ â†’ {best_ckp_path}")

    # # è¨“ç·´çµæŸå›å‚³æœ€ä½³çµæœ
    # return best_ckp_path, best_score, auroc_sp, aupro_px, student_encoder, student_decoder


if __name__ == '__main__':
    import argparse
    import pandas as pd
    import os
    import torch

    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser()
    parser.add_argument('--category', default='bottle', type=str)  # è¨“ç·´é¡åˆ¥
    parser.add_argument('--epochs', default=25, type=int)  # è¨“ç·´å›åˆæ•¸
    parser.add_argument('--arch', default='wres50', type=str)  # æ¨¡å‹æ¶æ§‹
    parser.add_argument('--bs', action='store', type=int, required=True)
    parser.add_argument('--lr', action='store', type=float, required=True)
    args = parser.parse_args()

    setup_seed(111)  # å›ºå®šéš¨æ©Ÿç¨®å­
    # save_visual_path = f"results/{args.arch}_{args.category}"
    save_pth_path = f"pths/best_{args.arch}_{args.category}"

    # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
    save_pth_dir = save_pth_path if save_pth_path else 'pths/best'
    os.makedirs(save_pth_dir, exist_ok=True)

    # é–‹å§‹è¨“ç·´ï¼Œä¸¦æ¥æ”¶æœ€ä½³æ¨¡å‹è·¯å¾‘èˆ‡çµæœ
    train(args.arch, args.category, args.epochs, save_pth_path)
    # best_ckp, auroc_px, auroc_sp, aupro_px, bn, decoder = train(
    #     args.arch, args.category, args.epochs, save_pth_path)

    # print(f"æœ€ä½³æ¨¡å‹: {best_ckp}")

    # # å­˜è¨“ç·´æŒ‡æ¨™åˆ° CSV
    # df_metrics = pd.DataFrame([{
    #     'Category': args.category,
    #     'Pixel_AUROC': auroc_px,
    #     'Sample_AUROC': auroc_sp,
    #     'Pixel_AUPRO': aupro_px,
    #     'Epochs': args.epochs
    # }])
    # metrics_name = f"metrics_{args.arch}_{args.category}.csv"
    # df_metrics.to_csv(metrics_name,
    #                   mode='a',
    #                   header=not os.path.exists(metrics_name),
    #                   index=False)

    # # ğŸ”¥ è¨“ç·´çµæŸå¾Œè‡ªå‹•ç”¢ç”Ÿå¯è¦–åŒ–çµæœ
    # visualizationDraem(args.arch,
    #               args.category,
    #               ckp_path=best_ckp,
    #               save_path=save_visual_path)
