import torch  # å¼•å…¥ PyTorch
from dataset import get_data_transforms  # å¾ dataset.py è¼‰å…¥è³‡æ–™è½‰æ›å‡½å¼
from torchvision.datasets import ImageFolder  # ç”¨æ–¼å½±åƒè³‡æ–™å¤¾çš„è³‡æ–™é›†
import numpy as np  # æ•¸å€¼è¨ˆç®—å¥—ä»¶
import random  # äº‚æ•¸æ§åˆ¶
import os  # æª”æ¡ˆç³»çµ±æ“ä½œ
from torch.utils.data import DataLoader  # PyTorch çš„è³‡æ–™è¼‰å…¥å™¨
from dataset import MVTecDataset  # MVTec è³‡æ–™é›†é¡åˆ¥
import torch.backends.cudnn as cudnn  # CUDA cuDNN åŠ é€Ÿ
import argparse  # å‘½ä»¤åˆ—åƒæ•¸è™•ç†
from test import evaluation, evaluation_draem, visualization, visualizationDraem, dream_evaluation, evaluation2, test  # æ¸¬è©¦ã€è©•ä¼°èˆ‡å¯è¦–åŒ–å‡½å¼
from torch.nn import functional as F  # å¼•å…¥ PyTorch çš„å‡½å¼ä»‹é¢
from model_unet import ReconstructiveSubNetwork, DiscriminativeSubNetwork  # å‡è¨­ä½ çš„ DRAEM å®šç¾©åœ¨ models/draem.py
from student_models import StudentReconstructiveSubNetwork, StudentDiscriminativeSubNetwork
from loss import FocalLoss, SSIM
from data_loader import MVTecDRAEMTrainDataset
from torch import optim
from data_loader_val import MVTecDRAEMValidationDataset
# æ–°å¢ç†±åŠ›åœ–å¯è¦–åŒ–æ‰€éœ€çš„å‡½å¼åº«
from PIL import Image
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
from tensorboard_visualizer import TensorboardVisualizer


def setup_seed(seed):
    # è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—å¯é‡ç¾
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è­‰çµæœå¯é‡ç¾
    torch.backends.cudnn.benchmark = False  # é—œé–‰è‡ªå‹•æœ€ä½³åŒ–æœå°‹


# è’¸é¤¾æå¤±å‡½æ•¸
def distillation_loss(teacher_features, student_features):
    # è¨ˆç®—å­¸ç”Ÿæ¨¡å‹èˆ‡æ•™å¸«æ¨¡å‹ç‰¹å¾µçš„ Cosine ç›¸ä¼¼åº¦æå¤±
    cos_loss = torch.nn.CosineSimilarity()  # åˆå§‹åŒ– CosineSimilarity
    if not isinstance(teacher_features, (list, tuple)):
        # å¦‚æœè¼¸å…¥ä¸æ˜¯ list æˆ– tupleï¼Œå°±è½‰æˆ listï¼Œæ–¹ä¾¿è¿­ä»£
        teacher_features, student_features = [teacher_features
                                              ], [student_features]

    loss = 0  # åˆå§‹åŒ–ç¸½æå¤±
    for i in range(len(teacher_features)):
        # å°‡ç‰¹å¾µå±•å¹³ï¼Œè¨ˆç®—æ¯å€‹ batch çš„ 1 - Cosine ç›¸ä¼¼åº¦ï¼Œå†å–å¹³å‡
        loss += torch.mean(1 - cos_loss(
            teacher_features[i].view(teacher_features[i].shape[0], -1),
            student_features[i].view(student_features[i].shape[0], -1)))
    return loss  # å›å‚³ç¸½è’¸é¤¾æå¤±


def generate_anomaly_map(student_rec,
                         gray_batch,
                         student_out_mask_sm,
                         mode='recon+seg'):
    """
    ç”Ÿæˆç¼ºé™·ç†±åŠ›åœ–
    mode:
        'recon'       : ä½¿ç”¨é‡å»ºèª¤å·® L2
        'seg'         : ä½¿ç”¨åˆ†å‰² softmax çš„ç¼ºé™·é€šé“
        'recon+seg'   : L2 é‡å»ºèª¤å·®èˆ‡åˆ†å‰²æ¦‚ç‡åŠ æ¬Š
    """
    if mode == 'recon':
        # L2 é‡å»ºèª¤å·®
        recon_error = torch.mean((student_rec - gray_batch)**2,
                                 dim=1,
                                 keepdim=True)  # [B,1,H,W]ï¼Œæ²¿é€šé“ç¶­åº¦å–å¹³å‡
        anomaly_map = recon_error  # ç¼ºé™·ç†±åŠ›åœ–å³é‡å»ºèª¤å·®
    elif mode == 'seg':
        # ä½¿ç”¨ç¼ºé™·åˆ†å‰² softmax çš„ç¬¬ 1 é€šé“ (å‡è¨­ 0 æ˜¯æ­£å¸¸, 1 æ˜¯ç¼ºé™·)
        anomaly_map = student_out_mask_sm[:, 1:, :, :]
    elif mode == 'recon+seg':
        # åŒæ™‚è€ƒæ…®é‡å»ºèª¤å·®èˆ‡åˆ†å‰²æ¦‚ç‡
        recon_error = torch.mean((student_rec - gray_batch)**2,
                                 dim=1,
                                 keepdim=True)  # è¨ˆç®—é‡å»ºèª¤å·®
        seg_prob = student_out_mask_sm[:, 1:, :, :]  # å–ç¼ºé™·æ¦‚ç‡
        anomaly_map = recon_error + seg_prob  # ç°¡å–®åŠ æ¬Šç›¸åŠ 
        anomaly_map = anomaly_map / anomaly_map.max()  # Normalize to [0,1]
    else:
        raise ValueError(f"Unknown mode {mode}")  # è‹¥ mode ä¸åˆæ³•ï¼Œä¸Ÿå‡ºéŒ¯èª¤

    return anomaly_map  # å›å‚³ç¼ºé™·ç†±åŠ›åœ–


def train(_arch_, _class_, epochs, save_pth_path):
    # è¨“ç·´æµç¨‹ä¸»å‡½æ•¸
    print(f"ğŸ”§ é¡åˆ¥: {_class_} | Epochs: {epochs}")

    device = 'cuda' if torch.cuda.is_available() else 'cpu'  # é¸æ“‡é‹ç®—è£ç½®
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: {device}")

    # æ•™å¸«æ¨¡å‹ (å·²è¼‰å…¥æ¬Šé‡ä¸¦è¨­ç‚º eval æ¨¡å¼)
    teacher_model = ReconstructiveSubNetwork(in_channels=3,
                                             out_channels=3)  # é‡å»ºå­ç¶²è·¯
    teacher_model_seg = DiscriminativeSubNetwork(in_channels=6,
                                                 out_channels=2)  # åˆ†å‰²å­ç¶²è·¯

    # === Step 2: è¼‰å…¥ checkpoint ===
    teacher_model_ckpt = torch.load(
        "DRAEM_seg_large_ae_large_0.0001_800_bs8_bottle_.pckl",
        map_location=device,
        weights_only=True)  # è¼‰å…¥æ•™å¸«é‡å»ºæ¨¡å‹æ¬Šé‡
    teacher_model_seg_ckpt = torch.load(
        "DRAEM_seg_large_ae_large_0.0001_800_bs8_bottle__seg.pckl",
        map_location=device,
        weights_only=True)  # è¼‰å…¥æ•™å¸«åˆ†å‰²æ¨¡å‹æ¬Šé‡

    teacher_model.load_state_dict(teacher_model_ckpt)  # å°‡æ¬Šé‡åŠ è¼‰åˆ°æ¨¡å‹
    teacher_model_seg.load_state_dict(teacher_model_seg_ckpt)

    # é‡è¦ï¼šè¼‰å…¥æ¬Šé‡å¾Œå†ç§»åˆ°è¨­å‚™
    teacher_model = teacher_model.to(device)
    teacher_model_seg = teacher_model_seg.to(device)
    teacher_model.eval()  # è¨­ç‚ºè©•ä¼°æ¨¡å¼ï¼Œä¸æ›´æ–°æ¬Šé‡
    teacher_model_seg.eval()

    # å­¸ç”Ÿæ¨¡å‹
    student_dropout_rate = 0.2  # Dropout ç‡ï¼Œå¯èª¿æ•´
    student_model = StudentReconstructiveSubNetwork(
        in_channels=3, out_channels=3,
        dropout_rate=student_dropout_rate)  # å­¸ç”Ÿé‡å»ºæ¨¡å‹
    student_model_seg = StudentDiscriminativeSubNetwork(
        in_channels=6, out_channels=2,
        dropout_rate=student_dropout_rate)  # å­¸ç”Ÿåˆ†å‰²æ¨¡å‹

    student_model = student_model.to(device)  # ç§»åˆ°é‹ç®—è£ç½®
    student_model_seg = student_model_seg.to(device)

    # === Step 3: å®šç¾©å­¸ç”Ÿæ¨¡å‹å„ªåŒ–å™¨å’Œå­¸ç¿’ç‡æ’ç¨‹å™¨ ===
    optimizer_weight_decay = 1e-5  # L2 æ­£å‰‡åŒ–
    optimizer = torch.optim.Adam([
        {
            "params": student_model.parameters(),
            "lr": args.lr,
            "weight_decay": optimizer_weight_decay  # L2 æ­£å‰‡åŒ–
        },
        {
            "params": student_model_seg.parameters(),
            "lr": args.lr,
            "weight_decay": optimizer_weight_decay  # L2 æ­£å‰‡åŒ–
        }
    ])
    scheduler = optim.lr_scheduler.MultiStepLR(
        optimizer,
        milestones=[args.epochs * 0.8, args.epochs * 0.9],  # å­¸ç¿’ç‡ä¸‹é™ç¯€é»
        gamma=0.2)  # æ¯æ¬¡ä¸‹é™ä¹˜ä»¥ 0.2

    # === Step 4: å®šç¾©æå¤±å‡½æ•¸å’Œè’¸é¤¾è¶…åƒæ•¸ ===
    loss_l2 = torch.nn.modules.loss.MSELoss()  # L2 æå¤±
    loss_ssim = SSIM()  # çµæ§‹ç›¸ä¼¼æ€§æå¤±
    loss_focal = FocalLoss()  # Focal Lossï¼Œç”¨æ–¼åˆ†å‰²

    # è’¸é¤¾æå¤±
    loss_distill_recon_fn = torch.nn.modules.loss.MSELoss()  # é‡å»ºè’¸é¤¾æå¤±
    loss_kldiv = torch.nn.KLDivLoss(reduction='batchmean')  # KL æ•£åº¦ï¼Œç”¨æ–¼åˆ†å‰²è’¸é¤¾

    # è’¸é¤¾è¶…åƒæ•¸
    T = 2.0  # æº«åº¦
    alpha = 0.5  # è’¸é¤¾æ¬Šé‡

    # === Step 5: æº–å‚™ Dataset å’Œ DataLoader ===
    print("Step 5: Preparing Dataset and DataLoader...")

    train_path = f'./mvtec/{_class_}/train'  # è¨“ç·´è³‡æ–™è·¯å¾‘
    anomaly_source_path = f'./dtd/images'  # ç¼ºé™·æ¨£æœ¬ä¾†æº
    dataset = MVTecDRAEMTrainDataset(train_path + "/good/",
                                     anomaly_source_path,
                                     resize_shape=[256, 256])  # è¨“ç·´é›†
    dataloader = DataLoader(dataset,
                            batch_size=args.bs,
                            shuffle=True,
                            num_workers=8)  # DataLoader

    # é©—è­‰é›†
    val_path = f'./mvtec/{_class_}/test'  # é©—è­‰è³‡æ–™è·¯å¾‘
    val_dataset = MVTecDRAEMValidationDataset(val_path,
                                              resize_shape=[256, 256])
    val_dataloader = DataLoader(
        val_dataset,
        batch_size=args.bs,
        shuffle=False,  # é©—è­‰é›†ä¸æ‰“äº‚
        num_workers=8)
    print("Validation DataLoader prepared.")

    visualizer_path = f'{_class_}/'
    visualizer = TensorboardVisualizer(log_dir=os.path.join(
        save_pth_path, visualizer_path))  # TensorBoard å¯è¦–åŒ–

    # === Step 6: æ ¸å¿ƒè¨“ç·´è¿´åœˆ ===
    print("Step 6: Starting the training loop...")
    best_val_loss = float('inf')  # åˆå§‹åŒ–æœ€ä½³é©—è­‰æå¤±
    n_iter = 0  # ç¸½è¿­ä»£è¨ˆæ•¸å™¨

    for epoch in range(args.epochs):
        student_model.train()  # è¨“ç·´æ¨¡å¼
        student_model_seg.train()

        running_loss = 0.0  # ç´¯è¨ˆæå¤±

        print(f"Epoch: {epoch+1}/{args.epochs}")
        for i_batch, sample_batched in enumerate(dataloader):
            # å–å¾— batch è³‡æ–™ï¼Œæ¯å€‹ batch åŒ…å«åŸå§‹ç°éšåœ–åƒã€å¢å¼·å¾Œåœ–åƒï¼Œä»¥åŠç•°å¸¸é®ç½©
            orig_batch = sample_batched["orig_image"].to(device)  # åŸå§‹å½©è‰²åœ–
            gray_batch = sample_batched["image"].to(
                device)  # åŸå§‹ç°éšåœ–ï¼Œé€åˆ° GPU æˆ– CPU
            aug_gray_batch = sample_batched["augmented_image"].to(
                device)  # å¢å¼·å¾Œçš„ç°éšåœ–åƒ
            anomaly_mask = sample_batched["anomaly_mask"].to(device)  # ç•°å¸¸å€åŸŸé®ç½©

            # --- æ•™å¸«æ¨¡å‹å‰å‘å‚³æ’­ ---
            with torch.no_grad():  # æ•™å¸«æ¨¡å‹ä¸æ›´æ–°æ¬Šé‡ï¼Œåªåšæ¨è«–
                teacher_rec = teacher_model(aug_gray_batch)  # æ•™å¸«æ¨¡å‹å°å¢å¼·å¾Œåœ–åƒåšé‡å»º
                # å°‡æ•™å¸«æ¨¡å‹é‡å»ºçµæœèˆ‡å¢å¼·åœ–åƒåˆä½µï¼Œå½¢æˆè¼¸å…¥çµ¦åˆ†å‰²æ¨¡å‹
                teacher_joined_in = torch.cat((teacher_rec, aug_gray_batch),
                                              dim=1)
                # æ•™å¸«æ¨¡å‹åˆ†å‰²é ­è¼¸å‡ºç•°å¸¸é®ç½©çš„ logits
                teacher_out_mask_logits = teacher_model_seg(teacher_joined_in)
                teacher_out_mask = F.softmax(teacher_out_mask_logits,
                                             dim=1)[:, 1, ...]  # å–ç•°å¸¸é¡åˆ¥æ¦‚ç‡

            # --- å­¸ç”Ÿæ¨¡å‹å‰å‘å‚³æ’­ ---
            student_rec = student_model(aug_gray_batch)  # å­¸ç”Ÿæ¨¡å‹å°å¢å¼·å¾Œåœ–åƒåšé‡å»º
            # å°‡å­¸ç”Ÿæ¨¡å‹é‡å»ºçµæœèˆ‡å¢å¼·åœ–åƒåˆä½µï¼Œå½¢æˆè¼¸å…¥çµ¦åˆ†å‰²æ¨¡å‹
            student_joined_in = torch.cat((student_rec, aug_gray_batch), dim=1)
            # å­¸ç”Ÿæ¨¡å‹åˆ†å‰²é ­è¼¸å‡ºç•°å¸¸é®ç½©çš„ logits
            student_out_mask_logits = student_model_seg(student_joined_in)
            student_out_mask = F.softmax(student_out_mask_logits,
                                         dim=1)[:, 1, ...]  # å–ç•°å¸¸é¡åˆ¥æ¦‚ç‡
            # --- å¯è¦–åŒ– ---
            if i_batch == 0:  # åªé¡¯ç¤ºç¬¬ä¸€å€‹ batchï¼Œé¿å…é¡¯ç¤ºå¤ªå¤š
                batch_idx = 0  # é¡¯ç¤º batch ä¸­ç¬¬ä¸€å¼µåœ–
                # å°‡å„å¼µåœ–è½‰æˆ numpy æ ¼å¼ï¼ŒC,H,W -> H,W,C
                orig_img = orig_batch[batch_idx].permute(1, 2, 0).cpu().numpy()
                gray_img = gray_batch[batch_idx, 0].cpu().numpy()
                aug_gray_img = aug_gray_batch[batch_idx, 0].cpu().numpy()
                teacher_rec_img = teacher_rec[batch_idx, 0].cpu().numpy()
                student_rec_img = student_rec[batch_idx, 0].cpu().numpy()
                teacher_mask_img = teacher_out_mask[batch_idx].cpu().numpy()
                student_mask_img = student_out_mask[batch_idx].cpu().numpy()
                anomaly_mask_img = anomaly_mask[batch_idx, 0].cpu().numpy()

                # ç”¨ visualizer å„²å­˜
                visualizer.add_image("åŸå§‹å½©è‰²åœ–", orig_img, epoch)
                visualizer.add_image("åŸå§‹ç°éšåœ–", gray_img, epoch, cmap='gray')
                visualizer.add_image("å¢å¼·å¾Œåœ–åƒ", aug_gray_img, epoch, cmap='gray')
                visualizer.add_image("æ•™å¸«æ¨¡å‹é‡å»º",
                                     teacher_rec_img,
                                     epoch,
                                     cmap='gray')
                visualizer.add_image("å­¸ç”Ÿæ¨¡å‹é‡å»º",
                                     student_rec_img,
                                     epoch,
                                     cmap='gray')
                visualizer.add_image("æ•™å¸«åˆ†å‰²çµæœ",
                                     teacher_mask_img,
                                     epoch,
                                     cmap='jet',
                                     alpha=0.7)
                visualizer.add_image("å­¸ç”Ÿåˆ†å‰²çµæœ",
                                     student_mask_img,
                                     epoch,
                                     cmap='jet',
                                     alpha=0.7)
                visualizer.add_image("åŸå§‹ç•°å¸¸é®ç½©",
                                     anomaly_mask_img,
                                     epoch,
                                     cmap='jet',
                                     alpha=0.5)
            # --- è¨ˆç®—æå¤± ---
            # 1. ç¡¬æå¤±
            loss_hard_l2 = loss_l2(student_rec, gray_batch)  # L2 æå¤±
            loss_hard_ssim = loss_ssim(student_rec, gray_batch)  # SSIM æå¤±
            student_out_mask_sm = F.softmax(student_out_mask_logits, dim=1)
            loss_hard_segment = loss_focal(student_out_mask_sm,
                                           anomaly_mask)  # åˆ†å‰²æå¤±
            loss_hard = loss_hard_l2 + loss_hard_ssim + loss_hard_segment  # ç¸½ç¡¬æå¤±

            # 2. è’¸é¤¾æå¤±
            loss_distill_recon = loss_distill_recon_fn(student_rec,
                                                       teacher_rec)  # é‡å»ºè’¸é¤¾
            p_student = F.log_softmax(student_out_mask_logits / T, dim=1)
            p_teacher = F.softmax(teacher_out_mask_logits / T, dim=1)
            loss_distill_segment = loss_kldiv(p_student, p_teacher) * (
                T * T)  # åˆ†å‰²è’¸é¤¾
            loss_distill = loss_distill_recon + loss_distill_segment  # ç¸½è’¸é¤¾æå¤±

            # 3. ç¸½æå¤±
            loss = (1 - alpha) * loss_hard + alpha * loss_distill  # åŠ æ¬Šçµ„åˆ

            # --- åå‘å‚³æ’­èˆ‡å„ªåŒ– ---
            optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
            loss.backward()  # åå‘å‚³æ’­
            optimizer.step()  # æ›´æ–°æ¬Šé‡

            running_loss += loss.item()  # ç´¯è¨ˆ batch æå¤±
            n_iter += 1  # æ›´æ–°ç¸½è¿­ä»£æ¬¡æ•¸

            if i_batch % 100 == 0:
                print(
                    f"  Batch {i_batch}/{len(dataloader)}, Total Loss: {loss.item():.4f}, "
                    f"Hard Loss: {loss_hard.item():.4f}, Distill Loss: {loss_distill.item():.4f}"
                )

        # è¨ˆç®— epoch å¹³å‡æå¤±
        epoch_loss = running_loss / len(dataloader)
        print(f"Epoch {epoch+1} Average Loss: {epoch_loss:.4f}")

        # === é©—è­‰éšæ®µ ===
        student_model.eval()  # è¨­ç‚ºè©•ä¼°æ¨¡å¼
        student_model_seg.eval()
        val_running_loss = 0.0

        # é¸æ“‡ä¸€å€‹ batch ç”¨æ–¼å¯è¦–åŒ–ï¼ˆç¢ºä¿å«ç¼ºé™·ï¼‰
        visualize_batch_done = False

        with torch.no_grad():  # é©—è­‰ä¸æ›´æ–°æ¬Šé‡
            for i_batch_val, sample_batched_val in enumerate(val_dataloader):
                gray_batch_val = sample_batched_val["image"].to(device)
                aug_gray_batch_val = sample_batched_val["augmented_image"].to(
                    device)
                anomaly_mask_val = sample_batched_val["anomaly_mask"].to(
                    device)

                # æ•™å¸«å‰å‘å‚³æ’­
                teacher_rec_val = teacher_model(aug_gray_batch_val)
                teacher_joined_in_val = torch.cat(
                    (teacher_rec_val, aug_gray_batch_val), dim=1)
                teacher_out_mask_logits_val = teacher_model_seg(
                    teacher_joined_in_val)

                # å­¸ç”Ÿå‰å‘å‚³æ’­
                student_rec_val = student_model(aug_gray_batch_val)
                student_joined_in_val = torch.cat(
                    (student_rec_val, aug_gray_batch_val), dim=1)
                student_out_mask_logits_val = student_model_seg(
                    student_joined_in_val)

                # è¨ˆç®—é©—è­‰æå¤±
                loss_hard_l2_val = loss_l2(student_rec_val, gray_batch_val)
                loss_hard_ssim_val = loss_ssim(student_rec_val, gray_batch_val)
                student_out_mask_sm_val = F.softmax(
                    student_out_mask_logits_val, dim=1)
                loss_hard_segment_val = loss_focal(student_out_mask_sm_val,
                                                   anomaly_mask_val)
                loss_hard_val = loss_hard_l2_val + loss_hard_ssim_val + loss_hard_segment_val

                loss_distill_recon_val = loss_distill_recon_fn(
                    student_rec_val, teacher_rec_val)
                p_student_val = F.log_softmax(student_out_mask_logits_val / T,
                                              dim=1)
                p_teacher_val = F.softmax(teacher_out_mask_logits_val / T,
                                          dim=1)
                loss_distill_segment_val = loss_kldiv(p_student_val,
                                                      p_teacher_val) * (T * T)
                loss_distill_val = loss_distill_recon_val + loss_distill_segment_val

                val_loss = (1 -
                            alpha) * loss_hard_val + alpha * loss_distill_val
                val_running_loss += val_loss.item()

                # åªç”Ÿæˆç¬¬ä¸€å€‹å«ç¼ºé™·çš„ batch çš„ç†±åŠ›åœ–ï¼Œé¿å…ç•«å‡ºå…¨æ˜¯æ­£å¸¸æ¨£æœ¬çš„åœ–
                if not visualize_batch_done and anomaly_mask_val.sum() > 0:
                    # ç”Ÿæˆç•°å¸¸ç†±åŠ›åœ–ï¼ˆé‡å»ºèª¤å·® + åˆ†å‰²çµæœï¼‰
                    anomaly_map_val = generate_anomaly_map(
                        student_rec_val,
                        gray_batch_val,
                        student_out_mask_sm_val,
                        mode='recon+seg')
                    # å¯è¦–åŒ–ç†±åŠ›åœ–
                    visualizer.visualize_image_batch(
                        anomaly_map_val, n_iter, image_name='val_anomaly_map')

                    # æå–åˆ†å‰²çµæœç•°å¸¸é€šé“
                    t_mask_val = student_out_mask_sm_val[:, 1:, :, :]

                    # å°‡å¢å¼·åœ–é€åˆ° TensorBoard
                    visualizer.visualize_image_batch(
                        aug_gray_batch_val,
                        n_iter,
                        image_name='val_batch_augmented')
                    # å°‡é‡å»ºç›®æ¨™ï¼ˆåŸå§‹åœ–ï¼‰é€åˆ° TensorBoard
                    visualizer.visualize_image_batch(
                        gray_batch_val,
                        n_iter,
                        image_name='val_batch_recon_target')
                    # å°‡å­¸ç”Ÿæ¨¡å‹é‡å»ºè¼¸å‡ºé€åˆ° TensorBoard
                    visualizer.visualize_image_batch(
                        student_rec_val,
                        n_iter,
                        image_name='val_batch_recon_out')
                    # å°‡çœŸå¯¦ç•°å¸¸æ©ç¢¼é€åˆ° TensorBoard
                    visualizer.visualize_image_batch(
                        anomaly_mask_val, n_iter, image_name='val_mask_target')
                    # å°‡å­¸ç”Ÿæ¨¡å‹åˆ†å‰²è¼¸å‡ºç•°å¸¸é€šé“é€åˆ° TensorBoard
                    visualizer.visualize_image_batch(t_mask_val,
                                                     n_iter,
                                                     image_name='val_mask_out')

                    visualize_batch_done = True  # æ¨™è¨˜å·²ç”Ÿæˆç†±åŠ›åœ–ï¼Œé¿å…é‡è¤‡

        epoch_val_loss = val_running_loss / len(val_dataloader)
        print(f"Epoch {epoch+1} Average Validation Loss: {epoch_val_loss:.4f}")

        # æª¢æŸ¥æ˜¯å¦æœ€ä½³æ¨¡å‹ï¼Œè‹¥æ˜¯å°±ä¿å­˜
        if epoch_val_loss < best_val_loss:  # âœ… ç”¨é©—è­‰é›†æå¤±
            best_val_loss = epoch_val_loss
            student_run_name = f"{_arch_}_student_{_class_}"
            torch.save(student_model.state_dict(),
                       os.path.join(save_pth_path, student_run_name + ".pckl"))
            torch.save(
                student_model_seg.state_dict(),
                os.path.join(save_pth_path, student_run_name + "_seg.pckl"))
            print(
                f"ğŸ‰ æ‰¾åˆ°æ–°çš„æœ€ä½³æ¨¡å‹ï¼Validation Loss: {best_val_loss:.4f}ã€‚å·²å„²å­˜è‡³ {save_pth_path}"
            )

        scheduler.step()  # æ›´æ–°å­¸ç¿’ç‡
    print("è¨“ç·´å®Œæˆï¼")  # è¨“ç·´çµæŸ


def generate_anomaly_heatmap(image_path,
                             student_model,
                             student_model_seg,
                             device,
                             resize_shape=[256, 256]):
    """
    ä½¿ç”¨è¨“ç·´å¥½çš„å­¸ç”Ÿæ¨¡å‹ç‚ºçµ¦å®šè¼¸å…¥å½±åƒç”Ÿæˆç•°å¸¸ç†±åŠ›åœ–ã€‚

    Args:
        image_path (str): è¼¸å…¥å½±åƒçš„è·¯å¾‘ã€‚
        student_model (torch.nn.Module): è¨“ç·´å¥½çš„å­¸ç”Ÿé‡å»ºå­ç¶²è·¯ã€‚
        student_model_seg (torch.nn.Module): è¨“ç·´å¥½çš„å­¸ç”Ÿåˆ¤åˆ¥å­ç¶²è·¯ã€‚
        device (str or torch.device): åŸ·è¡Œæ¨è«–çš„è£ç½® ('cuda' æˆ– 'cpu')ã€‚
        resize_shape (list): å½±åƒç¸®æ”¾çš„ç›®æ¨™å°ºå¯¸ (é«˜åº¦, å¯¬åº¦)ã€‚

    Returns:
        tuple: (numpy.ndarray, PIL.Image.Image) ç•°å¸¸ç†±åŠ›åœ– (NumPy é™£åˆ—) å’ŒåŸå§‹å½±åƒ (å·²ç¸®æ”¾çš„ PIL.Image ç‰©ä»¶)ã€‚
    """
    student_model.eval()  # è¨­å®šæ¨¡å‹ç‚ºè©•ä¼°æ¨¡å¼
    student_model_seg.eval()

    # å®šç¾©å½±åƒé è™•ç†è½‰æ›
    # èˆ‡ MVTecDRAEMTrainDataset ä¸­çš„æ­£è¦åŒ–ä¿æŒä¸€è‡´ (é€šå¸¸æ˜¯ [0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    transform = transforms.Compose([
        transforms.Resize(resize_shape),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])

    # è¼‰å…¥ä¸¦é è™•ç†å½±åƒ
    img = Image.open(image_path).convert('RGB')
    # ç‚ºäº†å¯è¦–åŒ–ï¼Œä¿ç•™ä¸€å€‹æœªæ­£è¦åŒ–ä½†å·²ç¸®æ”¾çš„åŸå§‹å½±åƒå‰¯æœ¬
    original_img_resized = img.resize((resize_shape[1], resize_shape[0]))
    img_tensor = transform(img).unsqueeze(0).to(device)  # æ–°å¢æ‰¹æ¬¡ç¶­åº¦

    with torch.no_grad():  # åœ¨æ¨è«–æ™‚ä¸è¨ˆç®—æ¢¯åº¦
        # å­¸ç”Ÿé‡å»ºç¶²è·¯æ¨è«–
        student_rec = student_model(img_tensor)

        # æº–å‚™å­¸ç”Ÿåˆ¤åˆ¥ç¶²è·¯çš„è¼¸å…¥ (é‡å»ºå½±åƒ + åŸå§‹å½±åƒ)
        student_joined_in = torch.cat((student_rec, img_tensor), dim=1)

        # å­¸ç”Ÿåˆ¤åˆ¥ç¶²è·¯æ¨è«–
        student_out_mask_logits = student_model_seg(student_joined_in)

        # æ‡‰ç”¨ Softmax å–å¾—ç•°å¸¸æ©Ÿç‡
        # åˆ¤åˆ¥ç¶²è·¯è¼¸å‡ºæœ‰ 2 å€‹é€šé“ï¼š[æ­£å¸¸æ©Ÿç‡ logits, ç•°å¸¸æ©Ÿç‡ logits]
        # æˆ‘å€‘å–ç•°å¸¸é¡åˆ¥ (é€šé“ 1) çš„æ©Ÿç‡
        anomaly_map = F.softmax(student_out_mask_logits,
                                dim=1)[:, 1, :, :].squeeze(0)

        # ç§»è‡³ CPU ä¸¦è½‰æ›ç‚º NumPy é™£åˆ—ä»¥ä¾¿å¯è¦–åŒ–
        anomaly_map_np = anomaly_map.cpu().numpy()

    return anomaly_map_np, original_img_resized


if __name__ == '__main__':
    import argparse
    import pandas as pd
    import os
    import torch

    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    parser = argparse.ArgumentParser()
    parser.add_argument('--category', default='bottle', type=str)  # è¨“ç·´é¡åˆ¥
    parser.add_argument('--epochs', default=25, type=int)  # è¨“ç·´å›åˆæ•¸
    parser.add_argument('--arch', default='wres50', type=str)  # æ¨¡å‹æ¶æ§‹
    parser.add_argument('--bs', action='store', type=int, required=True)
    parser.add_argument('--lr', action='store', type=float, required=True)
    # parser.add_argument('--test_image_path',
    #                     type=str,
    #                     help='è·¯å¾‘åˆ°ä¸€å€‹ç”¨æ–¼ç”Ÿæˆç†±åŠ›åœ–çš„æ¸¬è©¦å½±åƒ (è¨“ç·´å¾ŒåŸ·è¡Œ)ã€‚',
    #                     default=None)  # æ–°å¢åƒæ•¸
    # parser.add_argument(
    #     '--student_dropout_rate',
    #     type=float,
    #     default=0.2,
    #     help='å­¸ç”Ÿæ¨¡å‹è¨“ç·´å’Œè¼‰å…¥æ™‚ä½¿ç”¨çš„ Dropout Rateã€‚')  # å°‡ Dropout Rate å¯é…ç½®åŒ–
    args = parser.parse_args()

    setup_seed(111)  # å›ºå®šéš¨æ©Ÿç¨®å­
    save_pth_path = f"pths/best_{args.arch}_{args.category}"

    # å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾
    save_pth_dir = save_pth_path if save_pth_path else 'pths/best'
    os.makedirs(save_pth_dir, exist_ok=True)

    # é–‹å§‹è¨“ç·´ï¼Œä¸¦æ¥æ”¶æœ€ä½³æ¨¡å‹è·¯å¾‘èˆ‡çµæœ
    train(args.arch, args.category, args.epochs, save_pth_path)

    # # --- ç¼ºé™·æª¢æ¸¬ç†±åŠ›åœ–ç”Ÿæˆå€å¡Š ---
    # test_path = f'./mvtec/{args.category}/test'  # é©—è­‰è³‡æ–™è·¯å¾‘ (MVTec AD çš„æ¸¬è©¦é›†)
    # if test_path:
    #     print("\n--- æ­£åœ¨ç”Ÿæˆç¼ºé™·æª¢æ¸¬ç†±åŠ›åœ– ---")
    #     device = 'cuda' if torch.cuda.is_available() else 'cpu'

    #     # è¼‰å…¥å­¸ç”Ÿæ¨¡å‹æ¬Šé‡
    #     # é€™è£¡ä½¿ç”¨çš„ dropout_rate æ‡‰èˆ‡è¨“ç·´æ™‚ä½¿ç”¨çš„ä¿æŒä¸€è‡´
    #     student_model = StudentReconstructiveSubNetwork(
    #         in_channels=3,
    #         out_channels=3,
    #         dropout_rate=args.student_dropout_rate).to(device)
    #     student_model_seg = StudentDiscriminativeSubNetwork(
    #         in_channels=6,
    #         out_channels=2,
    #         dropout_rate=args.student_dropout_rate).to(device)

    #     student_run_name = f"{args.arch}_student_{args.category}"
    #     student_model_path = os.path.join(save_pth_path,
    #                                       student_run_name + ".pckl")
    #     student_model_seg_path = os.path.join(save_pth_path,
    #                                           student_run_name + "_seg.pckl")

    #     if os.path.exists(student_model_path) and os.path.exists(
    #             student_model_seg_path):
    #         student_model.load_state_dict(
    #             torch.load(student_model_path, map_location=device))
    #         student_model_seg.load_state_dict(
    #             torch.load(student_model_seg_path, map_location=device))
    #         print(
    #             f"âœ… å·²æˆåŠŸè¼‰å…¥å­¸ç”Ÿæ¨¡å‹æ¬Šé‡: {student_model_path} åŠ {student_model_seg_path}"
    #         )

    #         # ç”Ÿæˆç†±åŠ›åœ–
    #         anomaly_heatmap, original_image_resized = generate_anomaly_heatmap(
    #             test_path + args.test_image_path, student_model,
    #             student_model_seg, device)

    #         # å¯è¦–åŒ–çµæœ
    #         plt.figure(figsize=(12, 6))

    #         plt.subplot(1, 2, 1)
    #         plt.imshow(original_image_resized)
    #         plt.title("åŸå§‹å½±åƒ (Resized)")
    #         plt.axis('off')

    #         plt.subplot(1, 2, 2)
    #         # å°‡ç†±åŠ›åœ–ç–ŠåŠ åœ¨åŸå§‹å½±åƒä¸Š
    #         plt.imshow(original_image_resized, cmap='gray')  # èƒŒæ™¯é¡¯ç¤ºåŸå§‹å½±åƒ
    #         plt.imshow(anomaly_heatmap, cmap='jet', alpha=0.5, vmin=0,
    #                    vmax=1)  # ç–ŠåŠ ç†±åŠ›åœ–
    #         plt.colorbar(label='ç•°å¸¸æ©Ÿç‡')
    #         plt.title("ç¼ºé™·ç†±åŠ›åœ–")
    #         plt.axis('off')

    #         plt.tight_layout()
    #         plt.show()

    #         # (å¯é¸) å„²å­˜ç†±åŠ›åœ–åˆ°æª”æ¡ˆ
    #         heatmap_filename = os.path.join(
    #             save_pth_path,
    #             f"heatmap_{os.path.basename(args.test_image_path)}")
    #         plt.savefig(heatmap_filename)
    #         print(f"ç†±åŠ›åœ–å·²å„²å­˜è‡³: {heatmap_filename}")

    #     else:
    #         print(
    #             f"âŒ æ‰¾ä¸åˆ°å­¸ç”Ÿæ¨¡å‹æ¬Šé‡ï¼Œè«‹ç¢ºèªè·¯å¾‘: {student_model_path} æˆ– {student_model_seg_path} æ˜¯å¦å­˜åœ¨ã€‚"
    #         )
    # else:
    #     print("\nå¦‚éœ€ç”Ÿæˆç†±åŠ›åœ–ï¼Œè«‹åœ¨å‘½ä»¤åˆ—ä¸­æŒ‡å®š '--test_image_path <å½±åƒè·¯å¾‘>'ã€‚")
